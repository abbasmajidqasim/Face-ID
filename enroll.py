import cv2
import numpy as np
import os
from ultralytics import YOLO
from transformers import AutoImageProcessor, AutoModel
from PIL import Image
import torch


# =============================
# ØªØ­Ù…ÙŠÙ„ YOLO
# =============================
yolo = YOLO("yolov11n-face.pt")

# =============================
# ØªØ­Ù…ÙŠÙ„ ViT
# =============================
processor = AutoImageProcessor.from_pretrained("google/vit-large-patch16-224-in21k")
vit = AutoModel.from_pretrained("google/vit-large-patch16-224-in21k").eval()

device = "cuda" if torch.cuda.is_available() else "cpu"
vit.to(device)

DB_FILE = "vit_embeddings.npy"

# ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
if os.path.exists(DB_FILE):
    face_db = np.load(DB_FILE, allow_pickle=True).item()
else:
    face_db = {}

# Ø£Ø®Ø° Ø§Ø³Ù… Ø§Ù„Ø´Ø®Øµ
name = input("ğŸ“ Ø§Ø¯Ø®Ù„ Ø§Ø³Ù… Ø§Ù„Ø´Ø®Øµ: ").strip()

cap = cv2.VideoCapture(0)
embeddings = []

print("ğŸ“¸ ÙˆØ¬Ù‘Ù‡ ÙˆØ¬Ù‡Ùƒ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§ â€” Ø§Ø¶ØºØ· S Ù„Ø§Ù„ØªÙ‚Ø§Ø· embedding Ùˆ ESC Ù„Ù„Ø®Ø±ÙˆØ¬")

# =============================
# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø«ÙŠÙ„ ViT
# =============================
def get_vit_embedding(face_img):
    face_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(face_rgb)

    inputs = processor(images=pil_img, return_tensors="pt").to(device)

    with torch.no_grad():
        outputs = vit(**inputs)

    emb = outputs.last_hidden_state[:, 0, :].cpu().numpy().flatten()
    return emb


# =============================
# Ø­Ù„Ù‚Ø© Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ØªØ³Ø¬ÙŠÙ„
# =============================
while True:
    ret, frame = cap.read()
    if not ret:
        continue

    results = yolo(frame, verbose=False)[0]

    for box in results.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        face = frame[y1:y2, x1:x2]

        if face.size == 0:
            continue

        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)

    cv2.imshow("Enrollment - ViT", frame)

    key = cv2.waitKey(1)

    if key == ord('s') and face.size != 0:
        emb = get_vit_embedding(face)
        embeddings.append(emb)
        print("âœ” ØªÙ… Ø§Ù„ØªÙ‚Ø§Ø· embedding")

    if key == 27:
        break

cap.release()
cv2.destroyAllWindows()

if embeddings:
    face_db[name] = np.mean(embeddings, axis=0)
    np.save(DB_FILE, face_db)
    print(f"ğŸ”¥ ØªÙ… Ø­ÙØ¸ {name} Ø¯Ø§Ø®Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")
else:
    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªÙ‚Ø§Ø· Ø£ÙŠ Ø´ÙŠØ¡")
